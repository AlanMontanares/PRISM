{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5493a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from astroquery.hips2fits import hips2fits\n",
    "import sys \n",
    "import os\n",
    "\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from utils.sersic_functions import generate_random_pos\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a857aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wcs(ra, dec):\n",
    "    wcs = WCS(naxis=2)\n",
    "    wcs.wcs.crpix = [15.0, 15.0]\n",
    "    wcs.wcs.cdelt = [-6.944444445183e-5, 6.944444445183e-5]  # grados/píxel\n",
    "    wcs.wcs.crval = [ra, dec]\n",
    "    wcs.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n",
    "    wcs.wcs.cunit = [\"deg\", \"deg\"]\n",
    "    return wcs\n",
    "\n",
    "def get_galaxy_img(ra, dec, level, size):\n",
    "    \n",
    "    w = WCS(header={\n",
    "        'NAXIS': 2,\n",
    "        'NAXIS1': size,\n",
    "        'NAXIS2': size,\n",
    "        'CTYPE1': 'RA---TAN',\n",
    "        'CTYPE2': 'DEC--TAN',\n",
    "        'CDELT1': -6.94444461259988E-05 * (2 ** level),  \n",
    "        'CDELT2': 6.94444461259988E-05 * (2 ** level),  \n",
    "        'CRPIX1': size/2,\n",
    "        'CRPIX2': size/2,\n",
    "        'CUNIT1': 'deg',\n",
    "        'CUNIT2': 'deg',\n",
    "        'CRVAL1': ra,\n",
    "        'CRVAL2': dec,\n",
    "    })\n",
    "\n",
    "    result = hips2fits.query_with_wcs(\n",
    "        hips='CDS/P/PanSTARRS/DR1/r',\n",
    "        wcs=w,\n",
    "        get_query_payload=False,\n",
    "        format='fits')\n",
    "\n",
    "\n",
    "    r = result[0].data.byteswap().newbyteorder()\n",
    "    r = np.nan_to_num(r, 0)\n",
    "\n",
    "    return r\n",
    "\n",
    "def get_multires(df, idx, size, num_augmentations):\n",
    "    '''\n",
    "    Retorna la tupla (imgs, pos_host)\n",
    "\n",
    "    imgs: imagenes en multi resolucion centradas en la SN\n",
    "    pos_host: distancia desde el centro a la galaxia host en pixeles, en la forma (x,y)\n",
    "    '''\n",
    "    row = df.iloc[idx]\n",
    "    radius_sersic = row[\"rSerRadius\"]\n",
    "    ab_sersic = row[\"rSerAb\"]\n",
    "    phi_sersic = row[\"rSerPhi\"]\n",
    "\n",
    "    host_ra = row[\"host_ra\"]\n",
    "    host_dec = row[\"host_dec\"]\n",
    "\n",
    "    # Posición arbitraria\n",
    "\n",
    "    imagenes = []\n",
    "    posiciones = []\n",
    "    for x in range(num_augmentations):\n",
    "\n",
    "        # Se genera una posicion de SN centrada en el host\n",
    "        pos = generate_random_pos(\n",
    "            sersic_radius=radius_sersic,\n",
    "            sersic_ab=ab_sersic,\n",
    "            sersic_phi=phi_sersic,\n",
    "            img_size=600 # El radio maximo era 300 pix\n",
    "        )\n",
    "\n",
    "        wcs = get_wcs(host_ra, host_dec)\n",
    "        \n",
    "        # Le sumamos el centro a la posicion de la SN y obtenemos sus coordenadas (ra,dec)\n",
    "        ra_sn, dec_sn = wcs.pixel_to_world_values([pos + 14])[0]\n",
    "\n",
    "        # Obtenemos la imagen en multi-resolucion\n",
    "        multi = []\n",
    "        for i in range(5):\n",
    "            img = get_galaxy_img(ra_sn, dec_sn, level=i, size=size)\n",
    "            multi.append(img)\n",
    "\n",
    "        imagenes.append(np.array(multi))\n",
    "        posiciones.append(-pos) # Ahora la imagen esta centrada en la SN por lo que la posicion al host es lo opuesto\n",
    "\n",
    "    return np.stack(imagenes) , np.stack(posiciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96961ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\data\\SERSIC\\df_pasquet_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "640d45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = np.load(\"..\\data\\SERSIC\\X_train_pasquet_linear_p1_augmented_x10.npz\")\n",
    "X_train_1 = data_1[\"imgs\"]\n",
    "y_train_1 = data_1[\"pos\"]\n",
    "\n",
    "data_2 = np.load(\"..\\data\\SERSIC\\X_train_pasquet_linear_p2_augmented_x10.npz\")\n",
    "X_train_2 = data_2[\"imgs\"]\n",
    "y_train_2 = data_2[\"pos\"]\n",
    "\n",
    "data_3 = np.load(\"..\\data\\SERSIC\\X_train_pasquet_linear_p3_augmented_x10.npz\")\n",
    "X_train_3 = data_3[\"imgs\"]\n",
    "y_train_3 = data_3[\"pos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd1b836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_train_1, X_train_2, X_train_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ced39738",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate([y_train_1, y_train_2, y_train_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c748d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ceros = (X_train.sum((1,2))==0).any(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_idxs = np.array(range(len(mask_ceros)))[mask_ceros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "768025d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=30\n",
    "num_augmentations=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c1b3c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461/461 [13:52<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(missing_idxs):\n",
    "    while True:\n",
    "        try:\n",
    "            img, pos = get_multires(df, idx // num_augmentations, size=size, num_augmentations=1)\n",
    "\n",
    "            X_train[idx] = img[0].transpose(1, 2, 0)\n",
    "            y_train[idx] = pos\n",
    "\n",
    "            break  \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d38f572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_ceros = (X_train.sum((1,2))==0).any(1)\n",
    "mask_ceros.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e4ef4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f'..\\data\\SERSIC\\X_train_pasquet_augmented_x10.npz', imgs=X_train, pos=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5abce18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imgs', 'pos']\n",
      "(605460, 30, 30, 5) float32\n",
      "(605460, 2) float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"..\\\\data\\\\SERSIC\\\\X_train_pasquet_augmented_x10.npz\")\n",
    "\n",
    "print(data.files)  # Verifica que 'imgs' y 'pos' están presentes\n",
    "\n",
    "X_train = data[\"imgs\"]\n",
    "y_train = data[\"pos\"]\n",
    "\n",
    "print(X_train.shape, X_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
